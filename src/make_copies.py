# Copyright (C) 2021, Aryaman Sinha
# -*- coding: utf-8 -*-
"""make_copies.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fVNAV4WJ8pioMaDlRlw3JdAm8XPo-3bA
"""

# from google.colab import drive
# import os
# drive.mount('/content/drive/',force_remount=True)
# os.chdir('/content/drive/My Drive/data_generated/')

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import numpy as np
import time
import math
from keras.models import Model
from keras.layers import Dense, Input, Lambda
# from keras.applications.vgg16 import decode_predictions, preprocess_input
# from keras.applications.inception_v3 import  decode_predictions, preprocess_input
from keras.applications.resnet import  decode_predictions, preprocess_input
from attack import square_attack_l2, square_attack_linf
from l2_attack import CarliniL2
import scipy.io as sio
import utils
import sys
import os


def readimg(ff,key):
  f = "./testing_database/resnet/cw_l2/"+ff
  arr = sio.loadmat(f)
  img = arr[key]
  return img

def get_data():
    np.random.seed(42)
    from multiprocessing import Pool
    pool = Pool(16)
    f = "./testing_database/resnet/cw_l2/"
    test_data,orig_data=[],[]
    
    for x in os.listdir(f):
      if 'adv' in x:
        test_data.append(readimg(x,'adv'))
      if 'orig' in x:
        orig_data.append(readimg(x,'orig'))
          
    test_data = np.array(test_data)
    orig_data = np.array(orig_data)
    return test_data, orig_data, [x for x in os.listdir(f) if 'adv' in x]

def PSNR(img1,img2):
    mse = np.mean((img1-img2)**2)
    if mse==0:
        return 100
    return 20*math.log10(1/np.sqrt(mse))

class VGG16_:
  def __init__(self, session=None, use_log=False):
    self.image_size=224
    self.num_labels=1000
    self.num_channels=3

    input_= Input((224,224,3))
    input_1 = Lambda(lambda x: preprocess_input(x*255.0))(input_)
    if use_log:
      vgg_model = tf.keras.applications.VGG16(weights='imagenet',input_tensor=input_1)
    else:
      vgg_model = tf.keras.applications.VGG16(weights='imagenet',input_tensor=input_1,classifier_activation=None)
    self.model = Model(input_,vgg_model.output)

  def predict(self, data):
    return self.model(data)

class InceptionV3_:
  def __init__(self, session=None, use_log=False):
    self.image_size=299
    self.num_labels=1000
    self.num_channels=3

    input_= Input((299,299,3))
    input_1 = Lambda(lambda x: preprocess_input(x*255.0))(input_)
    if use_log:
      model = tf.keras.applications.InceptionV3(weights='imagenet',input_tensor=input_1)
    else:
      model = tf.keras.applications.InceptionV3(weights='imagenet',input_tensor=input_1,classifier_activation=None)
    self.model = Model(input_,model.output)

  def predict(self, data):
    return self.model(data)

class ResNet101_:
  def __init__(self, session=None, use_log=False):
    self.image_size=224
    self.num_labels=1000
    self.num_channels=3

    input_= Input((224,224,3))
    input_1 = Lambda(lambda x: preprocess_input(x*255.0))(input_)
    if use_log:
      model = tf.keras.applications.ResNet101(weights='imagenet',input_tensor=input_1)
    else:
      model = tf.keras.applications.ResNet101(weights='imagenet',input_tensor=input_1,classifier_activation=None)
    self.model = Model(input_,model.output)

  def predict(self, data):
    return self.model(data)

# CW attack to create copy
with tf.Session() as sess:
  model = ResNet101_(sess,use_log=False)
  inputs, orig_data, filenames = get_data()
  pred = np.argmax(model.model.predict(inputs),-1)
  targets = np.zeros((len(pred), 1000))
  targets[np.arange(len(targets)), pred] = 1
  timestart = time.time()
  i=0
  c=len(inputs)%100
  q=(len(inputs)//100)*100
  while(i<len(inputs)):
    if c!=0 and i==q:
      attack =  CarliniL2(sess, model, batch_size=c, max_iterations=10000, confidence=0,boxmin=0,boxmax=1,targeted=False) 
      adv = attack.attack(inputs[i:i+c], targets[i:i+c])
      adv = np.array(adv)
      for j in range(len(adv)):
        adv_class = decode_predictions(model.model.predict(adv[j:j+1]))[0][0][1]
        name = './multi_adv_database/cw_attack/adv/resnet/cw_l2/'+(filenames[i+j].split('_'))[0]+'_'+(filenames[i+j].split('_'))[1]+'_'+str(1)+'_'+adv_class
        sio.savemat(name+'.mat',{'multi':adv[j]})
      i=i+c
    else:
      attack =  CarliniL2(sess, model, batch_size=100, max_iterations=10000, confidence=0,boxmin=0,boxmax=1,targeted=False) 
      adv = attack.attack(inputs[i:i+100], targets[i:i+100])
      adv = np.array(adv)
      for j in range(len(adv)):
        adv_class = decode_predictions(model.model.predict(adv[j:j+1]))[0][0][1]
        name = './multi_adv_database/cw_attack/adv/resnet/cw_l2/'+(filenames[i+j].split('_'))[0]+'_'+(filenames[i+j].split('_'))[1]+'_'+str(1)+'_'+adv_class
        sio.savemat(name+'.mat',{'multi':adv[j]})
      i=i+100
  timeend = time.time()
  print("Took",timeend-timestart,"seconds to run",len(inputs),"samples.")

# Square attack to create copy
with tf.Session() as sess:
  model = VGG16_(sess,use_log=False)
  test_data, orig_data, filenames = get_data()
  pred = np.argmax(model.model.predict(test_data),-1)
  test_labels = np.zeros((len(pred), 1000))
  test_labels[np.arange(len(test_labels)), pred] = 1
  square_attack = square_attack_l2
  x_test = test_data
  p = 0.1
  eps = 1275/255
  n_iter = 100000
  n_cls = 1000
  loss = 'margin_loss'
  logits_clean = model.model.predict(x_test)
  corr_classified = logits_clean.argmax(1) == logits_clean.argmax(1)
  y_target = pred
  y_target_onehot = utils.dense_to_onehot(y_target, n_cls=n_cls)
  timestart = time.time()
  adv=[]
  i=0
  c=len(x_test)%100
  q=(len(x_test)//100)*100
  while(i<len(x_test)):
    if c!=0 and i==q:
      _,adv = square_attack(model, x_test[i:i+c], y_target_onehot[i:i+c], corr_classified[i:i+c], eps, n_iter,
      p, './metric_path_test/square_l2', False, loss)
      adv = np.array(adv)
      for j in range(len(x_test[i:i+c])):
        adv_class = decode_predictions(model.model.predict(adv[j:j+1]))[0][0][1]
        name =  './multi_adv_database/adv/vgg16/square_l2/cw_data/'+(filenames[i+j].split('_'))[0]+'_'+(filenames[i+j].split('_'))[1]+'_'+str(1)+'_'+adv_class
        sio.savemat(name+'.mat',{'multi':adv[j]})
      i=i+c

    else:
      _,adv = square_attack(model, x_test[i:i+100], y_target_onehot[i:i+100], corr_classified[i:i+100], eps, n_iter,
      p, './metric_path_test/square_l2', False, loss)
      adv = np.array(adv)
      for j in range(len(x_test[i:i+100])):
        adv_class = decode_predictions(model.model.predict(adv[j:j+1]))[0][0][1]
        name = './multi_adv_database/adv/vgg16/square_l2/cw_data/'+(filenames[i+j].split('_'))[0]+'_'+(filenames[i+j].split('_'))[1]+'_'+str(1)+'_'+adv_class
        sio.savemat(name+'.mat',{'multi':adv[j]})
      i=i+100
      
  timeend = time.time()
  print("Took",timeend-timestart,"seconds to run",len(x_test),"samples")

